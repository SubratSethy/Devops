Introduction to docker.
->Virtual Machine is advancement to Physical Servers 
->Containers is advancement to virtual machines.
Concept of virtual machine :
->When we using our personal personal laptop or physical servers we are not completely using the available resources -> CPU,RAM and hardwares etc.Organizations have thousands of servers.They are paying for these resources.
->To solve this -> Hypervisor used -> Hypervisor uses the concept of Virtualization -> Virtualiazation used to create lot of virtual machines (vm)or virtual servers on top of your physical servers.
                                                                                    -> vm is a virtual isolation of ps. -> each vms has its own operating system(os).
                                                                                                                        -> Because of separate os vms are logically separated from each other-> results in vms are very secure.  
                                                                                                                        -> on top of this os we run our application.
->Instead of running a application on a physical servers we can run a lot applications on lot of vms on a single physical servers.
->AWS install zen hypervisor on its physical servers->create EC2 instances(virtual machines).->while creating vms you define os(what is ram and cpu of vms)

Then why should we move to containers ?
-> while running applications on full capacity on vms it not uses 25 CPU,25GB RAM, we are not utilizing the complete resources of vms (ps:100CPU,100GB RAM ->into 4 vms each of 25CPU,25GB RAM).
-> So containers came to solve this problem.Problems of ps solved to some extent by vms ->Problems of vms solved to some extent by containers.
-> Containers doesnot have complete Operating System so they are not complete isolate from each other so there is security issue.
Architecture of Containers.
->Containers can be created by installing containorization platform example: Docker 
->2 ways of creating containers.->model 1:installing containorization platform example: Docker on physical servers which has os already installed on it .
                                ->model 2:installing containorization platform example: Docker on vms which are installed on physical servers which has os already installed on it.
                                ->Now-a days everyone using model-2 as it is based on vms and cloud as there is less maintaince as we are using vms.
                                ->for model-1 we have do maintain a system administrator for security fixes and new pathes we have to maintain a datacenter. 
->Containers are  light weight in nature as they donnot have complete os.->They use the required resources form base os or host os of vms and physical servers they are installed on.
->Containers have minimal os and base image-> containers are package of appliaction,application libraries, sytsem dependencies->your applicatioon may require system dependencies that may be python, java etc.
->If we require any other shared libraries except that present on containers that will be used from host os. 
->If we want to create image of your vm we will create a snapshot(image) of our vm ->Size of snapshots(image) may be 1GB(minimal with all dependencies are installed)or may be 2GB.
->If we consider vm with container then size of the snapshots of container fall between 100(minimal) to 500 MB(it increases to 500 if application has lot of dependencies )
->so there is significant drop in the size when we consider container.As conbtainer lightweight->easy to ship and deploy one docker container from one containerzation platform to another platform and deploy image to kubernetes.
->In docker image we use a base image that contains system dependencies,application and application libraries ->they will form docker image or docker container.->so,containers have minimalstic os.
Docker LifeCycle
->first write docker file ->using docker commands sent this file to docker engine->use docker commands to create docker image from docker file->write commands to create docker container from docker image.
                                                                                  -> docker build command                                     -> docker run command
->Docker is very much dependent on docker engine if docker fails then all the conatainers will go down it is single point of failure.
->When docker image ios created it creates a lot of layers so it take lot memory space.
->To solve these problems Buildah comes -> we write shellscript and put all buildah commands in it->it will create docker image.
How to push the docker image into a public and private registry by doing this we share this to customers.
How to reduce the size of the docker image by definition  the size of the image should be small but we by keep adding packages to docker image its size get increased.
->when containers not running they donot use resources from the kernal(part of host opertaing system)
->when vms or EC2 instances are created they have os with kernal.
->All the containers have some system dependencies it should be there as there should be some part of logoical isolation between the containers as they can use all resources from kernal any hacker can get into kubernetes cluster
 and in one container can get into all the containers.
->To provide a better picture of files and folders that containers base images have and files and folders that containers use from host operating system (not 100 percent accurate -> varies from base image to base image). 
  Refer below.

Files and Folders in containers base images
->These files and folders make a logical isolation from one container to another-> one container doesnot share this with another container.These files and folders doesnot use by the kernal these are part container. 
    /bin: contains binary executable files, such as the ls, cp, and ps commands.

    /sbin: contains system binary executable files, such as the init and shutdown commands.

    /etc: contains configuration files for various system services.

    /lib: contains library files that are used by the binary executables.

    /usr: contains user-related files and utilities, such as applications, libraries, and documentation.

    /var: contains variable data, such as log files, spool files, and temporary files.

    /root: is the home directory of the root user.
Files and Folders that containers use from host operating system
->These are the part of the kernal or host operting system.
    The host's file system: Docker containers can access the host file system using bind mounts, which allow the container to read and write files in the host file system.

    Networking stack: The host's networking stack is used to provide network connectivity to the container. Docker containers can be connected to the host's network directly or through a virtual network.

    System calls: The host's kernel handles system calls from the container, which is how the container accesses the host's resources, such as CPU, memory, and I/O.

    Namespaces: Docker containers use Linux namespaces to create isolated environments for the container's processes. Namespaces provide isolation for resources such as the file system, process ID, and network.

    Control groups (cgroups): Docker containers use cgroups to limit and control the amount of resources, such as CPU, memory, and I/O, that a container can access.
->you can run n number of containers on your vms depending on how much resources they are using from host os->when onbe container is not running they can allow other containers to use the resources from host os.
->As vms have individual os vm1 can not use kernal related resources from vm2.
    
What is Docker ?
Docker is a containerization platform that provides easy way to containerize your applications, which means, using Docker you can build container images, run the images to create containers and also push these containers to container regestries such as DockerHub, Quay.io and so on.

In simple words, you can understand as containerization is a concept or technology and Docker Implements Containerization.

Docker Architecture ?
1.Docker Client
when we use Docker Client or Docker CLI we execute some commands that received by docker daemon(when installing docker we actually installing docker daemon).->dockerdaemon executes all the commands gives output as docker image and docker container.
->By using Docker daemon we push docker container into docker registry by using docker commands.
->If docker daemon goes down then all containers and docker will not work or goes down.
2.Docker Host contain docker daemon.
3.Docker Regisrty
Docker LifeCycle
There are three important things,
1.docker build -> builds docker images from Dockerfile->Docker daemon executes this command given as input by docker cli.
2.docker run -> runs container from docker images 
3.docker push -> push the container image to public/private regestries to share the docker images or docker container.
Daemon service LifeCycle:
Daemon receives request from docker cli.
->first as a user you have to  write a docker file->this file contains set of instructions for example you tell daemon to create ubuntu base image and put the given source code into base image
->run specific command->if it is node js run npm command if it is python run pip command-> so that all application libraries and system dependencies get installed inside the image->run set of commands so that application executes.
->use docker build to submit the docker file to docker daemon to create docker daemon->docker run to create docker container as output it contains application libraries,system dependencies.
->By public registry you send containers to uers they download it use it.
->If we do manually first download the application and create vms and run on it->export the port and lot of things
->these problems solved by the docker->helps to reduce complexity->increase efficiency as execute docker image all the things get created as docker image contains all the things.
Understanding the terminology (Inspired from Docker Docs)
Docker daemon
The Docker daemon (dockerd) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. A daemon can also communicate with other daemons to manage Docker services.

Docker client
The Docker client (docker) is the primary way that many Docker users interact with Docker. When you use commands such as docker run, the client sends these commands to dockerd, which carries them out. 
The docker command uses the Docker API. The Docker client can communicate with more than one daemon.

Docker Desktop
Docker Desktop is an easy-to-install application for your Mac, Windows or Linux environment that enables you to build and share containerized applications and microservices.
Docker Desktop includes the Docker daemon (dockerd), the Docker client (docker), Docker Compose, Docker Content Trust, Kubernetes, and Credential Helper. For more information, see Docker Desktop.

Docker registries
A Docker registry stores Docker images. Docker Hub is a public registry that anyone can use, and Docker is configured to look for images on Docker Hub by default. You can even run your own private registry.
you create private registry within Docker hub which can be accessed by some users with valid permissions.

When you use the docker pull or docker run commands, the required images are pulled from your configured registry. When you use the docker push command, your image is pushed to your configured registry. Docker objects

When you use Docker, you are creating and using images, containers, networks, volumes, plugins, and other objects. This section is a brief overview of some of those objects.

Dockerfile
Dockerfile is a file where you provide the steps to build your Docker Image.

Images
An image is a read-only template with instructions for creating a Docker container. Often, an image is based on another image, with some additional customization. For example, you may build an image which is based on the ubuntu image, but installs the Apache web server and your application, as well as the configuration details needed to make your application run.

You might create your own images or you might only use those created by others and published in a registry. To build your own image, you create a Dockerfile with a simple syntax for defining the steps needed to create the image and run it. Each instruction in a Dockerfile creates a layer in the image. When you change the Dockerfile and rebuild the image, only those layers which have changed are rebuilt. This is part of what makes images so lightweight, small, and fast, when compared to other virtualization technologies.
